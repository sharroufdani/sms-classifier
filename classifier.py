# -*- coding: utf-8 -*-
"""classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1biVb8BHD4O9lxXO3WeNij5fqgsGJqFKB
"""

!pip install pandas numpy scikit-learn matplotlib seaborn streamlit pyngrok


import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import nltk
nltk.download('punkt')

from google.colab import files
import pandas as pd

# Upload CSV
uploaded = files.upload()

# Get the uploaded file name
train_csv = list(uploaded.keys())[0]

# Read CSV and define columns explicitly
# Assuming the CSV has two columns: message and label
df_train = pd.read_csv(train_csv, header=None, names=['message', 'label'])

# Display first rows
df_train.head()

# Numeric features
df_train['message_length'] = df_train['message'].apply(len)
df_train['num_digits'] = df_train['message'].apply(lambda x: sum(c.isdigit() for c in str(x)))
df_train['num_upper'] = df_train['message'].apply(lambda x: sum(c.isupper() for c in str(x)))
df_train['num_special'] = df_train['message'].apply(lambda x: sum(not c.isalnum() and not c.isspace() for c in str(x)))

# TF-IDF vectorization
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(stop_words='english')
X_text = vectorizer.fit_transform(df_train['message'])

import numpy as np
numeric_features = ['message_length','num_digits','num_upper','num_special']
X_train = np.hstack((X_text.toarray(), df_train[numeric_features].values))
y_train = df_train['label']

from sklearn.tree import DecisionTreeClassifier

clf = DecisionTreeClassifier(max_depth=5, random_state=42)
clf.fit(X_train, y_train)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.tree import DecisionTreeClassifier
# import matplotlib.pyplot as plt
# import seaborn as sns
# import joblib
# 
# st.title("SMS Classification: A2P vs P2P")
# 
# # --- Upload CSV for prediction ---
# uploaded_file = st.file_uploader("Upload a CSV file with messages", type="csv")
# if uploaded_file:
#     df_new = pd.read_csv(uploaded_file, header=None, names=['message'])
#     st.write("Uploaded messages:")
#     st.dataframe(df_new)
# 
#     # --- Feature Engineering ---
#     df_new['message_length'] = df_new['message'].apply(lambda x: len(str(x)))
#     df_new['num_digits'] = df_new['message'].apply(lambda x: sum(c.isdigit() for c in str(x)))
#     df_new['num_upper'] = df_new['message'].apply(lambda x: sum(c.isupper() for c in str(x)))
#     df_new['num_special'] = df_new['message'].apply(lambda x: sum(not c.isalnum() and not c.isspace() for c in str(x)))
# 
#     # --- Load trained classifier & vectorizer ---
#     clf = joblib.load('clf.joblib')
#     vectorizer = joblib.load('vectorizer.joblib')
#     numeric_features = ['message_length','num_digits','num_upper','num_special']
# 
#     # Transform text
#     X_text_new = vectorizer.transform(df_new['message'])
#     X_new = np.hstack((X_text_new.toarray(), df_new[numeric_features].values))
# 
#     # Predict
#     df_new['predicted_label'] = clf.predict(X_new)
#     st.write("Predicted Labels:")
#     st.dataframe(df_new)
# 
#     # Feature importance
#     importances = clf.feature_importances_
#     all_features = list(vectorizer.get_feature_names_out()) + numeric_features
#     feat_imp = pd.DataFrame({'feature': all_features, 'importance': importances}).sort_values(by='importance', ascending=False).head(10)
# 
#     fig, ax = plt.subplots(figsize=(10,6))
#     sns.barplot(x='importance', y='feature', data=feat_imp, palette='viridis', ax=ax)
#     st.pyplot(fig)
#

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Combine TF-IDF features + numeric features
all_features = list(vectorizer.get_feature_names_out()) + ['message_length', 'num_digits', 'num_upper', 'num_special']

# Get feature importance from the trained Decision Tree
importances = clf.feature_importances_

# Put into a DataFrame
feat_imp = pd.DataFrame({
    'feature': all_features,
    'importance': importances
})

# Sort by importance
feat_imp = feat_imp.sort_values(by='importance', ascending=False)
feat_imp.head(20)  # Show top 20 features

import joblib
joblib.dump(clf, 'clf.joblib')
joblib.dump(vectorizer, 'vectorizer.joblib')

!pip install pyngrok streamlit

!ngrok authtoken #add your ngrok token

from pyngrok import ngrok

# Kill any existing tunnels
ngrok.kill()

# Start ngrok tunnel on port 8501
public_url = ngrok.connect(8501)
print("Streamlit public URL:", public_url)

# Run Streamlit app
!streamlit run app.py &
